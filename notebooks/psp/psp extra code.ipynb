{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"psp extra code.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMiDRgZXkeoWZ4yPtGVo9g9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":218},"id":"GOMiXcYl-YnQ","executionInfo":{"status":"error","timestamp":1637961852568,"user_tz":-60,"elapsed":5871,"user":{"displayName":"Vasco","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04380586738115098026"}},"outputId":"3509b29c-6d60-4a19-e1ac-09a7831ed93b"},"source":["# Output of shape 1000, confidence scores for each of the imagenet classes\n","# Now we will save this model.\n","import torch.onnx\n","from torch.autograd import Variable\n","\n","# torch.onnx.export(resnet,\n","#                   inp_batch,\n","#                   \"resnet18.onnx\",\n","#                   export_params=True,\n","#                   opset_version=10)\n","\n","# # I am not using a GPU here, if you are, move it to cuda\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device = \"cpu\"\n","\n","\n","def export_onnx_model(model, onnx_model_path):\n","    with torch.no_grad():\n","        model.to(device)\n","\n","        vec_to_inject = np.random.randn(1, 512).astype('float32')\n","        _, latent_to_inject = model(torch.from_numpy(vec_to_inject).to(\"cpu\"),\n","                                  input_code=True,\n","                                  return_latents=True)\n","\n","\n","        # Format input image into a batch format the model can use\n","        inp_batch = transformed_image1.unsqueeze(0)\n","\n","        inputs = (inp_batch.float(),\n","                  {\"latent_mask\": latent_mask,\n","                  \"inject_latent\": latent_to_inject})\n","        \n","        torch.onnx.export(model,                                            \n","                          inputs,\n","                          onnx_model_path,                                  \n","                          opset_version=10,\n","                          verbose=True,                                 \n","                          # do_constant_folding=True,\n","                          # export_params=True,               \n","                          input_names=['input_ids',                         \n","                                       'input_code',\n","                                       'return_latents'])\n","        \n","        print(\"ONNX Model exported to {0}\".format(onnx_model_path))\n","\n","\n","\n","export_onnx_model(net,  \"output/mnist.onnx\")\n","\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-f0a09c49b24a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mexport_onnx_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"output/mnist.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"]}]},{"cell_type":"code","metadata":{"id":"3Rt-IGvEIjbP"},"source":["# https://colab.research.google.com/github/tugot17/data-science-blog/blob/master/_notebooks/2020-09-21-Exporting-lightning-model-to-onnx.ipynb#scrollTo=HjmPOz7EkNt1\n","\n","# Export the model\n","torch.onnx.export(model,                     # model being run\n","                  ##since model is in the cuda mode, input also need to be\n","                  X.to(\"cuda\"),              # model input (or a tuple for multiple inputs)\n","                  \"model_troch_export.onnx\", # where to save the model (can be a file or file-like object)\n","                  export_params=True,        # store the trained parameter weights inside the model file\n","                  opset_version=10,          # the ONNX version to export the model to\n","                  do_constant_folding=True,  # whether to execute constant folding for optimization\n","                  input_names = ['input'],   # the model's input names\n","                  output_names = ['output'], # the model's output names\n","                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n","                                'output' : {0 : 'batch_size'}})"],"execution_count":null,"outputs":[]}]}