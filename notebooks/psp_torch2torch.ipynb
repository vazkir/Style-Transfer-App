{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vascomeerman/Coding/Harvard/CS215/Project/Style-Transfer-App\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/python3.9/site-packages/cv2.cpython-39-darwin.so, 10): Library not loaded: @rpath/libvpx.7.dylib\n  Referenced from: /Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/libavcodec.58.134.100.dylib\n  Reason: no suitable image found.  Did find:\n\t/Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/libvpx.7.dylib: mach-o, but not built for platform macOS\n\t/Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/libvpx.7.dylib: mach-o, but not built for platform macOS\n\t/Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/python3.9/site-packages/../../libvpx.7.dylib: mach-o, but not built for platform macOS\n\t/Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/libvpx.7.dylib: mach-o, but not built for platform macOS\n\t/Users/vascomeerman/miniforge3/envs/MLOpsProject/bin/../lib/libvpx.7.dylib: mach-o, but not built for platform macOS",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/50/tbft5tg57dbb77hkln_b5v3r0000gn/T/ipykernel_55825/2506953577.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# from datasets import augmentations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcustom_psp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor2im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_input_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcustom_psp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpSp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Coding/Harvard/CS215/Project/Style-Transfer-App/custom_psp/utils/common.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/python3.9/site-packages/cv2.cpython-39-darwin.so, 10): Library not loaded: @rpath/libvpx.7.dylib\n  Referenced from: /Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/libavcodec.58.134.100.dylib\n  Reason: no suitable image found.  Did find:\n\t/Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/libvpx.7.dylib: mach-o, but not built for platform macOS\n\t/Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/libvpx.7.dylib: mach-o, but not built for platform macOS\n\t/Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/python3.9/site-packages/../../libvpx.7.dylib: mach-o, but not built for platform macOS\n\t/Users/vascomeerman/miniforge3/envs/MLOpsProject/lib/libvpx.7.dylib: mach-o, but not built for platform macOS\n\t/Users/vascomeerman/miniforge3/envs/MLOpsProject/bin/../lib/libvpx.7.dylib: mach-o, but not built for platform macOS"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import pprint\n",
    "from argparse import Namespace\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# sys.path.append(\".\")\n",
    "# sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "# from datasets import augmentations\n",
    "from custom_psp.utils.common import tensor2im, log_input_image\n",
    "from custom_psp.models.psp import pSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the psp repo in our shared folder (I believe)\n",
    "psp_path = \"/content/drive/MyDrive/StyleTransferProject/PSP/v3_pixel2style2pixel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of shape 1000, confidence scores for each of the imagenet classes\n",
    "# Now we will save this model.\n",
    "import torch.onnx\n",
    "\n",
    "# # I am not using a GPU here, if you are, move it to cuda\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "\n",
    "def export_onnx_model(model, onnx_model_path):\n",
    "    with torch.no_grad():\n",
    "        # Bring full model to cpu for conversion\n",
    "        # model.to(device)\n",
    "\n",
    "        # Format input image into a batch format the model can use\n",
    "        # inp_batch = transformed_image1.unsqueeze(0)\n",
    "        inp_batch = torch.randn(1, 3, 256, 256).to(device)\n",
    "\n",
    "\n",
    "        # Run the model once on the same input we give it for onnx to run\n",
    "        # _, _ = model(img_tensor.float(), randomize_noise=False, return_latents= True)\n",
    "        print(\"\\n\\n --------------ONNXX LETS GO ------------------\\n\\n\")\n",
    "\n",
    "        # Inputs needed for onnx to run 1 inference session so it can determine the graph it needs to convert\n",
    "        inputs = (inp_batch.float(),\n",
    "                  {\"randomize_noise\": False,\n",
    "                  \"return_latents\": True})\n",
    "        \n",
    "        # Convert our pytroch model to onnx, so we can later on convert it to tf\n",
    "        torch.onnx.export(model,                                            \n",
    "                          inputs,\n",
    "                          onnx_model_path,                                  \n",
    "                          opset_version=14,\n",
    "                          do_constant_folding=True,\n",
    "                          # See: https://github.com/pytorch/fairseq/issues/3395\n",
    "                          # operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,\n",
    "                          export_params=True,\n",
    "                          input_names=['input'],\n",
    "                          output_names=['output'],               \n",
    "                          # input_names=['input_ids',                         \n",
    "                          #              'input_code',\n",
    "                          #              'return_latents']\n",
    "                          )\n",
    "        \n",
    "        print(\"ONNX Model exported to {0}\".format(onnx_model_path))\n",
    "\n",
    "\n",
    "\n",
    "def export_new_model():\n",
    "    ckpt2 = torch.load(model_path, map_location='cpu')\n",
    "\n",
    "    # update the training options\n",
    "    opts2 = ckpt2['opts']\n",
    "    if device == \"cpu\":\n",
    "        opts2['device'] = \"cpu\"\n",
    "\n",
    "    opts2['checkpoint_path'] = model_path\n",
    "    if 'learn_in_w' not in opts2:\n",
    "        opts2['learn_in_w'] = False\n",
    "    if 'output_size' not in opts2:\n",
    "        opts2['output_size'] = 1024\n",
    "\n",
    "\n",
    "    opts2 = Namespace(**opts2)\n",
    "    new_net = pSp(opts2)\n",
    "    new_net.eval()\n",
    "\n",
    "    if device != \"cpu\":\n",
    "        new_net.cuda() # Don't move model to cuda for conversion\n",
    "    else:\n",
    "    print(f\"No cuda -> Running on {device}\")\n",
    "\n",
    "    export_onnx_model(new_net, \"../output/psp_clean_cpu3.onnx\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77ed5795d16ccc9261959c2cdd3d7136049904981f0ebcd029416055b8f109ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('MLOpsProject': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
